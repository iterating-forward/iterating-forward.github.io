---
layout: post
title: "Running a Yearly Retrospective That Doesn't Waste Everyone's Time"
date: 2026-01-16
categories: scrum agile teams
---

Most yearly retrospectives fail. They become three hours of performative reflection where the same people talk, nobody remembers what actually happened in March, and you leave with action items that will never get done.

## What Doesn't Work

**The "What Went Well / What Didn't" marathon**

Take your normal retrospective format and stretch it across 12 months. Watch people struggle to remember Q1.

This fails because human memory doesn't work that way. Psychologists call it recency bias: we overweight recent events because they're still in working memory, while older memories fade or distort. December dominates the conversation. February might as well not have happened.

The U.S. Army figured this out decades ago. Their After Action Review process requires documented evidence of what actually happened, not what people remember. Undocumented insights have a "half-life of hours" - wait too long without records, and the real lessons are lost.

**The action item factory**

You leave with 27 action items. The facilitator feels productive. Everyone else knows those sticky notes are going straight into the void.

Action items compete with delivery work. Delivery work always wins.

**The highlight reel**

Leadership-driven retrospectives that celebrate everything the team shipped. "Look at all our accomplishments!"

The Army's AAR guidance is explicit: review both successes and failures with equal honesty. If you only review failures, people associate the process with blame. If you only review successes, you miss the learning.

**The unstructured feelings dump**

"Let's talk about how we *feel* about the year."

Without structure, you get surface-level "I feel good about our progress" - or someone opens wounds that need more than a meeting to address. Feelings matter, but they need a container: a specific moment on the timeline, a concrete event to anchor them.

## What Actually Works

**Build a timeline before the meeting**

Pull together artifacts from the year:
- Major releases and their dates
- Team changes (who joined, who left)
- Significant incidents
- Key metrics

This grounds the conversation in what actually happened, not what people think happened. You counter recency bias by putting Q1 evidence in front of people so they can't unconsciously skip it.

**Use the ORID framework**

ORID (Observation, Reflection, Interpretation, Decision) sequences the conversation so you examine shared data before proposing changes. It's similar to the military's After Action Review, which compares intended outcomes to actual outcomes before discussing improvements.

**Observation** (10 min): Review the pre-built timeline together. Add missing events. No judgments yet - just facts.

**Reflection** (15 min): Silent activity. Everyone marks the timeline - green for energizing moments, red for frustrating ones. No debate. This captures individual responses before groupthink takes over.

**Interpretation** (40 min): Now you discuss. Where do the green dots cluster? The red ones? What was happening during the high points that wasn't happening during the low points? What patterns repeat?

**Decision** (20 min): Based on the patterns, pick one or two experiments for next year. Not a list of everything that needs fixing. One or two things the team actually commits to trying.

The total is 85 minutes. Don't stretch it. After two hours, energy dies.

**Frame with a single question**

A year is too long to discuss without focus. Use: "What do we want to be true about this team in 12 months that isn't true today?"

Everything feeds into answering that question.

**Stay at the right altitude**

The yearly retrospective is for macro patterns. "We keep having Friday incidents" is a regular retrospective item. "Our on-call model isn't sustainable" is a yearly conversation.

If you're diving into specific technical solutions, you've gone too deep. Note it, park it, move on.

## The Real Goal

The yearly retrospective isn't about generating action items. It's about building shared understanding of what the year actually looked like - so the team can align on what to try next.

The Army's AAR goal isn't a list of fixes. It's self-discovery: teams figure out for themselves what worked and what didn't. The facilitator guides but doesn't dictate conclusions.

Three outcomes mean the meeting worked:
1. The team has a common, evidence-based memory of the year
2. They understand when they were at their best and worst - and why
3. They've committed to one or two specific experiments

Not a transformation plan. Just honest reflection and one or two real commitments.

---

## Sources

- [Wharton: After-Action Reviews](https://executiveeducation.wharton.upenn.edu/thought-leadership/wharton-at-work/2021/07/after-action-reviews-simple-tool/)
- [U.S. Army FM 7-0: After Action Reviews](https://www.first.army.mil/Portals/102/FM%207-0%20Appendix%20K.pdf)
- [Scribbr: Recency Bias](https://www.scribbr.com/research-bias/recency-bias/)
- [Humanizing Work: End-of-Year Retro Format](https://www.humanizingwork.com/our-favorite-end-of-year-retro-format/)
